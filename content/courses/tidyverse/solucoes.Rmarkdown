---
title: "Soluções"
date: 2021-05-25
summary: Soluções dos exercícios
type: book
draft: false
---

Soluções dos exercícios.

## `readr`, `tibble`, `tidyr`

```{r}
# Não esqueça dos pacotes!
library(tidyverse)
```


1. Como você importaria o banco "epa78.csv"

```{r}
file <- readr_example("epa78.txt")
```

Primeiro, é bom verificar como estão dispostas as informações no arquivo texto

```{r}
read_lines(file, n_max = 10)

```

Ao identificar que se trata de um arquivo colunado, mas que as colunas são separadas por espaços, escolho o read_fwf com o fwf_empty.

```{r}
dic <- fwf_empty(file)

df <- read_fwf(file, col_positions = dic)
df
```

2. Importe o banco "challenge.csv" e resolva os problemas com o tipo da coluna.

Ao verificar as primeiras 10 linhas do banco, podemos notar algo estranho

```{r}
file <- readr_example("challenge.csv")

read_lines(file, n_max = 10)
```

Parece ser um arquivo csv comum, com duas colunas, mas uma delas parece ter apenas NAs. Se a gente proceder com a importação padrão, chegaremos em

```{r}
df <- read_csv(file)
df
```


No console de vocês, deve aparecer que foram importadas as colunas x como double e y como logical. Mas uma chuva de "parsing failures", indicando que expected = 1/0/T/F/TRUE/FALSE, actual = 2015-01-16.

Na verdade, ao tentar adivinhar o tipo de colunas, o readr lê as primeiras 1000 observações em busca de um padrão. Você pode resolver esse problema:

```{r}
# 1. Aumentando o número de observações utilizadas para adivinhar as colunas
df <- read_csv(file, guess_max = 1001)

# A específicação da coluna Y agora é <date>
df

# 2. escolhendo diretamente o tipo de coluna antes da importação
tipos <- cols(
  y = col_date()
)

df <- read_csv(file, col_types = tipos)

# Mesmo resultado
df
```

3. Com o banco sala_aula dado a seguir, transforme-o para que ele contenha as variáveis nome, avaliação e nota.

```{r}
sala_aula <- tribble(
 ~name,    ~teste1,  ~teste2,  ~prova1,
 "Billy",  "<NA>",   "D"   ,   "C",
 "Suzy",   "F",      "<NA>",   "<NA>",
 "Lionel", "B",      "C"   ,   "B",
 "Jenny",  "A",      "A"   ,   "B"
)

```

É sempre bom começar planejando o banco que queremos construir. Queremos um banco que tenha 3 variáveis: o nome, o tipo de prova aplicada e a nota de cada aluno. Para isso, precisamos colocar os nomes das colunas teste1, teste2 e prova1 numa variável e os valores das células em outra. Vamos chamar essas colunas de "avaliação" e "nota", elas formam um par. 

Agora vamos chamar `pivot_wider` e especificar esses argumentos.

```{r}
sala_aula %>% pivot_longer(
  # Primeiro, identificamos as colunas que serão modificadas
  cols = c(teste1, teste2, prova1),
  # Agora, indicamos os nomes das colunas que receberão
  # os nomes das colunas transformadas
  names_to = "avaliacao",
  # os valores das células
  values_to = "nota"
)
```

4. Transforme o banco `relig_income` para que ele contenha as colunas religião, renda e frequência.

```{r}
relig_income
```

O banco relig_income parece ter uma organização em que temos 2 variáveis, mas uma delas está numa coluna "religion" e a outra está em 10 colunas, "income". Queremos um banco que tenha 3 colunas: a religião, o nível de renda, e o número de pessoas em cada combinação das duas primeiras.

Como no exerício anterior, vamos chamar pivot_longer e especificar

```{r}
relig_income %>% pivot_longer(
  
  # As colunas a serem modificadas, notem o uso de ':' para selecionar várias
  # colunas em sequência
  cols = `<$10k`:`Don't know/refused`,
  
  # Variável recebe os nomes da antiga coluna
  names_to = "nivel_renda",
  
  # Variável recebe os valores das células
  values_to = "contagem"
  
)
```

5. Transforme o banco `billboard` para que ele contenha apenas uma coluna "semana" e uma coluna com a posição da música no ranking.

> Dica, você pode selecionar várias colunas usando o atalho wk1:wk76

```{r}
billboard
```

Da mesma forma como fizemos nos anteriores, queremos transformar as várias wk1:wk76 em um par de colunas, uma que me diga a semana e a outra que me diga em que posição no ranking a música estava.

```{r}
billboard %>% pivot_longer(
  # Colunas que serão transformadas
  cols = wk1:wk76,
  # Nome da variável que receberá os nomes das colunas
  names_to = "semana",
  # Nome da variável que receberá os valores das células
  values_to = "posicao_rank",
  # Nesse caso, uso o argumento opcional para eliminar os NAs
  values_drop_na = TRUE
  # Experimente mudar este argumento para FALSE e veja o resultado
  # Quando uma música não está mais nas paradas, ela recebe NA. Acho
  # justificado excluir os NAs nesse caso.
)
```

6. Experimente fazer o caminho inverso dos exercícios 3 a 5, devolvendo os datasets ao seu formato original. O que você observou?

Vou começar enxugando os códigos anteriores para criar os resultados que produzimos e salvá-los em objetos.

```{r}
sala_aula_long <- 
  sala_aula %>% pivot_longer(
    cols = c(teste1, teste2, prova1),
    names_to = "avaliacao",
    values_to = "nota"
  )

relig_income_long <- 
  relig_income %>% pivot_longer(
    cols = `<$10k`:`Don't know/refused`,
    names_to = "nivel_renda",
    values_to = "contagem"
  )

billboard_long <- 
  billboard %>% pivot_longer(
    cols = wk1:wk76,
    names_to = "semana",
    values_to = "posicao_rank",
    values_drop_na = TRUE
  )

sala_aula_long
relig_income_long
billboard_long
```

O caminho inverso desses bancos de dados, é utilizar `pivot_wider`. Aqui, vamos escolher um par de colunas que contém:

1. O nome das colunas que queremos criar
2. O valor que queremos passar para as células dessas novas colunas

Vamos ver exemplos comentados como no anterior

```{r}
sala_aula_long %>% pivot_wider(
  
  # Aqui, identificamos colunas que NÃO SERÃO MODIFICADAS
  # É o contrário de pivot_longer. Por padrão, são todas as que não são
  # mencionadas na transformação, mas para deixar bem claro, 
  # vou deixar explícito.
  id_cols = name,
  
  # Variável com os nomes para as novas colunas
  names_from = avaliacao,
  
  # Variável com os valores para as células
  values_from = nota
)

relig_income_long %>% pivot_wider(
  # Colunas não modificadas
  id_cols = religion,
  
  # Variável com os nomes para as novas colunas
  names_from = nivel_renda,
  
  # Variável com os valores para as células
  values_from = contagem
)

billboard_long %>% pivot_wider(
  # Colunas não modificadas
  id_cols = c(artist, track, date.entered),
  
  # Variável com os nomes para as novas colunas
  names_from = semana,
  
  # Variável com os valores para as células
  values_from = posicao_rank
)

```

Tanto `pivot_longer` quanto `pivot_wider` tem mais argumentos para lidar com situações complexas, como quando você precisa aplicar transformações em variáveis antes de reformatar o banco ou precisa utilizar múltiplas colunas, mas eu deixo isso para vocês descobrirem por conta própria quando estiverem confortáveis com a sintaxe básica.

7. O que os argumentos `extra` e `fill` em separate fazem? Utilize o exemplo a seguir como guia.

```{r}
tibble(x = c("a,b,c", "d,e,f,g", "h,i,j")) %>% 
  separate(x, c("um", "dois", "tres"))

tibble(x = c("a,b,c", "d,e", "f,g,i")) %>% 
  separate(x, c("um", "dois", "tres"))
```

Por padrão, `separate` espera que todas as colunas sendo separadas tenham o mesmo comprimento. Por exemplo, no primeiro caso, indicamos que vamos criar três novas colunas, chamadas de "um", "dois" e "tres". Mas os vetores tem tamanhos diferentes. Um deles tem 4 letras ao invés de 3. No segundo exemplo, um deles tem duas letras ao invés de três. Esse tipo de situação é bastante comum quando lidamos com erros de digitação. Então, o que fazer com o elemento que está sobrando ou faltando?

```{r}
# Sobrando
tibble(x = c("a,b,c", "d,e,f,g", "h,i,j")) %>% 
  separate(x, c("um", "dois", "tres"), extra = "warn") # avise que ocorreu (padrão)

tibble(x = c("a,b,c", "d,e,f,g", "h,i,j")) %>% 
  separate(x, c("um", "dois", "tres"), extra = "drop") # descarte o que sobrou

tibble(x = c("a,b,c", "d,e,f,g", "h,i,j")) %>% 
  separate(x, c("um", "dois", "tres"), extra = "merge") # junte com o último

# Note especialmente no último caso o que ocorreu com as colunas.

# Faltando
tibble(x = c("a,b,c", "d,e", "f,g,i")) %>% 
  separate(x, c("um", "dois", "tres"), fill = "warn") # avise e preencha a direita

tibble(x = c("a,b,c", "d,e", "f,g,i")) %>% 
  separate(x, c("um", "dois", "tres"), fill = "left") # preencha a esquerda

tibble(x = c("a,b,c", "d,e", "f,g,i")) %>% 
  separate(x, c("um", "dois", "tres"), fill = "right") # preencha a direta

# Note na sua saída do R como ficou a tibble e onde foram colocados NAs
# em cada caso
```

8. Tanto `unite` como `separate` possuem um argumento `remove`. Pra que ele serve e quando você o utilizaria no valor `FALSE`?

Acho que a melhor forma de compreender isso é utilizar um banco de dados. Vamos pegar aquele da população retirado da Wikipédia.

```{r}
populacao <- tribble(
  ~Rank, ~Country, ~Population,	~'% of world', ~Day, ~Month, ~Year, ~Source,
  1L,         "China",    1411778724, "17.9%",  "1", "Nov", "2020",       "Seventh Census on 2020",
  2L,         "India",    1377123716, "17.5%", "19", "May", "2021", "National population clock[3]",
  3L, "United States",     331695937, "4.22%", "19", "May", "2021", "National population clock[4]",
  4L,     "Indonesia",     271350000, "3.45%", "31", "Dec", "2020",  "National annual estimate[5]",
  5L,      "Pakistan",     225200000, "2.86%",  "1", "Jul", "2021",             "UN projection[2]",
  6L,        "Brazil",     213154869, "2.71%", "19", "May", "2021", "National population clock[6]",
  7L,       "Nigeria",     211401000, "2.69%",  "1", "Jul", "2021",             "UN projection[2]",
  8L,    "Bangladesh",     170689832, "2.17%", "19", "May", "2021", "National population clock[7]",
  9L,        "Russia",     146171015, "1.86%",  "1", "Jan", "2021",  "National annual estimate[8]",
  10L,       "Mexico",     126014024, "1.60%",  "2", "Mar", "2020",        "2020 census result[9]"
)
populacao
```

Vamos ver dois exemplos, um com `unite` e outro com `separate` para exemplificar o que `remove` faz.

```{r}
# Unir as colunas Day, Month, Year, remove = TRUE
populacao %>% unite(Data, Day, Month, Year, remove = TRUE) # padrão
# Unir as colunas Day, Month, Year, remove = FALSE
populacao %>% unite(Data, Day, Month, Year, remove = FALSE)

# Vejam o que aconteceu com as colunas nos dois bancos.
```

Agora com `separate`: Separar a coluna `year` em século e ano, apenas como exemplo

```{r}
# remove = TRUE, padrão
populacao %>% separate(Year, c("seculo", "ano"), sep = 2, remove = TRUE)

# remove = FALSE
populacao %>% separate(Year, c("seculo", "ano"), sep = 2, remove = FALSE)

# Vejam o que aconteceu com as colunas nos dois bancos.
```

Eu gosto de utilizar esse argumento quando eu tenho dúvida sobre o resultado e quero fazer inspeção visual para detectar eventuais problemas na separação ou junção. Uma vez que estou satisfeito com o resultado, em geral eu uso o `remove=TRUE`. Vocês tem que decidir se precisam manter as colunas originais ou se a coluna transformada é o suficiente.

9. Compare o argumento `values_fill` em `pivot_wider` e `fill` em `complete`. Qual é a diferença?

A resposta curta é simples: em `pivot_wider`, podemos ter aqueles missings "implícitos" que não apareciam no nosso banco longo e, durante a transformação, eles viram `NA`s nas colunas. Ó argumento `values_fill` indica um valor para ser preenchido no lugar de `NA`. 

Em `complete`, temos uma situação similar. O que fazer quando for encontrada uma combinação de valores no banco longo que é um "missing implícito"? Você pode especificar um valor padrão para preenchê-lo.

São funções similares, mas uma funciona sem reformatar o banco e a outra durante o processo de reformatação. Veja um exemplo abaixo com aquela `tibble` das ações.

```{r}
acoes <- tibble(
  ano   = c(2015, 2015, 2015, 2015, 2016, 2016, 2016),
  qdr   = c(   1,    2,    3,    4,    2,    3,    4),
  lucro = c(1.88, 0.59, 0.35,   NA, 0.92, 0.17, 2.66)
)

acoes

# Vamos supor que o NA implícito significa que a empresa teve 
# lucro = 0 naquele quadrimestre.

# pivot_wider, values_fill
acoes %>% pivot_wider(
  id_cols = ano,
  names_from = qdr,
  values_from = lucro,
  values_fill = 0
)

# complete, fill
acoes %>% complete(ano, qdr, fill = list(lucro = 0))
```

Note o resultado. E note também que `values_fill` em `pivot_wider` é um pouco mais criterioso na hora de fazer as transformações.

## `stringr`, `forcats` e `dplyr`

```{r}
library(nycflights13)
```


1. Encontre os vôos que:

  1. Atrasaram mais de duas horas
    
```{r}
flights %>% filter(dep_delay > 120)
```
    
    
  2. Com destino a Houston (`IAH` ou `HOU`)
    
```{r}
flights %>% filter(dest %in% c("IAH", "HOU"))
```
  
  3. Operados pela United, American ou Delta

```{r}
unique(flights$carrier)
flights %>% filter(carrier %in% c("UA", "AA", "DL"))
```
    
  4. Decolaram entre julho e setembro
    
```{r}
flights %>% filter(between(month, 7, 9))
```
    
  5. Chegaram com mais de duas horas de atraso, mas não decolaram com atraso
    
```{r}
flights %>% filter(arr_delay > 120, dep_delay <= 0)
```
    
  6. Atrasaram mais de uma hora para decolar, mas recuperaram mais de 30 minutos durante o voo
    
```{r}
flights %>% filter(dep_delay > 60, dep_delay - arr_delay >= 30)
```
    
  7. Decolaram entre a meia-noite e 6 da manhã (inclusive)
    
```{r}
flights %>% filter(between(hour, 0, 5) | (hour == 6 & minute == 0))
```
    
2. Reordene suas colunas para encontrar os voos mais rápidos (maior velocidade de voo).

```{r}
flights %>% 
  select(air_time, distance) %>% 
  mutate(speed = distance/air_time) %>% 
  arrange(desc(speed))
```

3. Teste várias maneiras diferentes de selecionar as variáveis `dep_time`, `dep_delay`, `arr_time` e `arr_delay` usando as várias helper functions de `select`.

```{r}
flights %>% select(dep_time, dep_delay, arr_time, arr_delay)

flights %>% select(starts_with("dep"), starts_with("arr"))

flights %>% select(starts_with(c("dep", "arr")))

flights %>% select(matches("^arr|^dep"))

flights %>% select(!starts_with(c("sched", "car")) & contains(c("dep", "arr")))

flights %>% select(ends_with(c("time", "delay")) & !starts_with(c("sched", "air")))
```


4. As variáveis `dep_time` e `sched_dep_time` estão num formato incorreto (veja `?flights`). Converta-as com `mutate` para um valor em minutos passados desde a meia-noite. Dica: utilize `%/%` e `%%`.

```{r}
flights %>% mutate(
  dep_hour         = dep_time %/% 100,
  dep_minute       = dep_time %% 100,
  sched_dep_hour   = sched_dep_time %/% 100,
  sched_arr_minute = sched_arr_time %% 100
)

# Há uma outra solução com separate!
flights %>% 
  separate(
    col = dep_time,
    into = c("dep_hour", "dep_minute"),
    sep = 1,
    # Esse argumento é importante! Teste com FALSE para ver a diferença
    convert = TRUE) %>% 
  separate(
    col = sched_dep_time,
    into = c("sched_dep_hour", "sched_dep_minute"),
    sep = 1,
    convert = TRUE)
```

Existe uma outra solução possível para essa questão usando manipulação de strings, com `str_sub` também. Fica como desafio!

Pensando na legibilidade do código e na flexibilidade da abordagem, qual das duas soluções acima você implementaria? `mutate` ou duas `separate`? Reflita.

5. O que o código abaixo está fazendo? Porque mesmo após o código abaixo continuam existindo diferenças entre os valores das variáveis `air_time` e `travel_time`?

```{r}
flights %>% 
  select(air_time, dep_time, arr_time, dep_delay, arr_delay) %>% 
  mutate(dep_hour = dep_time %/% 100,
         dep_min = dep_time %% 100,
         dep_time2 = dep_hour * 60 + dep_min,
         arr_hour = arr_time %/% 100,
         arr_min = arr_time %% 100,
         arr_time2 = arr_hour * 60 + arr_min,
         travel_time = arr_time2 - dep_time2) %>% 
  select(-dep_hour, -dep_min, -arr_hour, -arr_min)
```

Essa tem uma resposta mais qualitativa. A primeira parte é parecida com a questão anterior, mas estamos manualmente tentando calcular os tempos de viagem. Acontece que os valores não batem com os tempos de vôo identificados no banco. Isso se deve a pelo menos três questões distintas. 

- Uma delas diz respeito ao registro dos tempos, a definição de `air_time` pode não estar considerando tempos em que o avião está manobrando ou em solo ou mesmo podem existir erros de preenchimento. 
- A segunda diz respeito ao fuso horário distinto entre aeroportos de saída e chegada, que complica o cálculo dos tempos reais, então nosso cálculo está muito cru para identificar isso.
- A última questão são os vôos longos, que começam em um dia e terminam no dia seguinte, que podem prejudicar nosso método de cálculo. Para corrigir alguns desses problemas, você precisaria escrever um código que minimamente levasse essas questões em consideração. Como esse não é o objetivo do curso, eu deixo para quem quiser tentar. [Há uma solução postada aqui](https://jrnold.github.io/r4ds-exercise-solutions/transform.html#exercise-5.5.2).

6. Use o stringr para concatenar as seguintes strings em uma frase

```{r}
x <- "."
y <- "feliz"
w <- "acordei"
z <- "hoje"

str_c(z, w, y, sep = " ") %>% 
  str_c(x, sep = "") %>% 
  str_to_sentence()
```

7. Corrija as inconsistências nas colunas país, primeiro_nome, segundo_nome e crie uma nova coluna nomes contendo as duas anteriores. No final, ordene o banco em ordem alfabética.

```{r}
df <- 
  tibble::tribble(
    ~pais,    ~primeiro_nome, ~segundo_nome,
    # -------|----------------|-------------|
    "BRASIL", "ISABELA",       "MARTINS",
    "Brasil", "Eduardo",       "cabellos",
    "brasil", "márcia",         "pinto",
    "bRaSiL", "rogério",        "Marinho",
  )

# Sem dplyr
df$pais <- str_to_title(df$pais)
df$primeiro_nome <-  str_to_title(df$primeiro_nome)
df$segundo_nome <- str_to_title(df$segundo_nome)

df <- df %>% tidyr::unite(nomes, primeiro_nome, segundo_nome, sep = " ")
df[ str_order(df$nomes), ]

# Com dplyr
df <- 
  tibble::tribble(
    ~pais,    ~primeiro_nome, ~segundo_nome,
    # -------|----------------|-------------|
    "BRASIL", "ISABELA",       "MARTINS",
    "Brasil", "Eduardo",       "cabellos",
    "brasil", "márcia",         "pinto",
    "bRaSiL", "rogério",        "Marinho",
  )

df %>% 
  mutate(pais = str_to_title(pais),
         primeiro_nome = str_to_title(primeiro_nome),
         segundo_nome = str_to_title(segundo_nome)) %>% 
  unite(nomes, primeiro_nome, segundo_nome, sep = " ") %>% 
  arrange(str_order(nomes))
```

8. Transforme a string `c("Seu nome", "Seu sobrenome da mãe", "Seu sobrenome do pai")` na string `"SEU SOBRENOME DO PAI, sua inicial do nome. sua inicial da mãe."`, como numa citação. Veja o exemplo abaixo:

```{r}
# Transforme
c("Vinícius", "de Souza", "Maia")

# Resultado
"MAIA, V. S."


x <- c("Vinícius", "de Souza", "Maia")
x[1] <- str_sub(x[1], 1, 1) %>% str_c(".")
x[2] <- str_sub(x[2], 4, 4) %>% str_c(".")
x[3] <- str_to_upper(x[3])
str_c(c(x[3], x[1], x[2]), collapse = " ")
```


9. DESAFIO: Nos microdados da área de saúde, é comum que a variável idade esteja registrada da seguinte forma: "150", "219", "312", "471". Esses códigos indicam primeiro qual a unidade de medida da idade e segundo o valor desta unidade, 1 = horas, 2 = dias, 3 = meses, 4 = anos. Proponha um código usando `stringr` para transformar o vetor abaixo em um valor numérico.

```{r}
# Não precisa se preocupar com essa parte
x <- as.character(round(c(
  runif(25, 100, 124),
  runif(25, 201, 230),
  runif(25, 301, 312),
  runif(25, 401, 499)
)))

# Como você transformaria esse vetor em número?
x

# Esse exercício é um pouco mais difícil mesmo!
x %>% str_extract("\\d")

tibble(
  tipo_idade = str_sub(x, 1, 1),
  idade = str_sub(x, 2, 3),
  idade_anos =
    if_else(
      str_detect(tipo_idade, "1"),
      as.numeric(idade) / (24 * 30 * 12),
      if_else(
        str_detect(tipo_idade, "2"),
        as.numeric(idade) / (30 * 12),
        if_else(
          str_detect(tipo_idade, "3"),
          as.numeric(idade) / 12,
          as.numeric(idade)
        )
      )
    )
) %>% 
  print(n = Inf)
```

Ao invés de utilizar essas chamadas recursivas de `if_else`, que são muito ruins de ler, como você poderia reescrever a condição usando `case_when`?

10. Explore as contagens da variável `rincome` em `gss_cat`, ela ficaria bem representada num gráfico? De qual tipo?

```{r}
gss_cat %>% count(rincome)
```

Em geral, contagens de variáveis ficam bem em gráficos de barras ou visualizações equivalentes, em que é possível comparar visualmente as contagens das diversas categorias. Mais sobre isso na aula do `ggplot2`.

11. Qual a religião mais comum em `gss_cat`? Qual o partido (`partyid`) mais popular?

```{r}
# Religião
gss_cat %>% count(relig) %>% arrange(desc(n))

# Partido
gss_cat %>% count(partyid) %>% arrange(desc(n))
```

12. A que religião se refere a variável `denom`? Você pode descobrir isso fazendo uma tabela de contagens?

Você pode chamar count com várias variáveis para fazer uma tabulação cruzada.

```{r}
gss_cat %>% count(relig, denom) %>% print(n = Inf)
```

13. Como você poderia diminuir o número de categorias da variável `rincome` do banco `gss_cat`?

A melhor função para redução de fatores é `fct_collapse`. Veja como ficam a coluna original e a transformada.

```{r}
gss_cat2 <- 
  gss_cat %>% 
  # Aqui vou salvar em "rincome2" para a gente poder ver as duas
  mutate(rincome2 = fct_collapse(
    rincome,
    "Non-response" = c("No answer", "Don't know", "Refused", "Not applicable"),
    "Até 5k"       = c("$4000 to 4999", "$3000 to 3999", "$1000 to 2999", "Lt $1000"),
    "5k-10k"       = c( "$8000 to 9999", "$7000 to 7999", "$6000 to 6999", "$5000 to 5999"),
    "10k-20k"      = c("$15000 - 19999", "$10000 - 14999"),
    "20k+"         = c("$25000 or more", "$20000 - 24999"))) %>% 
  select(rincome, rincome2)

# E veja as contagens
gss_cat2 %>% count(rincome)
gss_cat2 %>% count(rincome2)
```

## `ggplot2`

1. O que tem de errado no código abaixo? Por que os pontos não ficaram azuis?

```{r}
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy, color = "blue"))
```

Os pontos não ficam azuis porque você não está especificando cores! Dentro da função `aes()` você está especificando variáveis para serem mapeadas a uma escala de cores. Portanto, o `ggplot` interpreta "blue" como uma variável sem nome que tem o valor "blue" e mapeia ela para a escala de cores padrão, que é vermelha. Se você quer controlar apenas a "aparência" dos pontos e não está preocupada em mapear nenhuma variável, você pode passar essa estética fora da função `aes()`.

```{r}
ggplot(data = mpg) + 
  geom_point(
    mapping = aes(x = displ, y = hwy), # aqui acabam os mapeamentos estéticos
    color = "blue", # alteração apenas na aparência do geom
    size = 2, # alteração apenas na aparência do geom
    shape = 6 # alteração apenas na aparência do geom
    ) 

```


2. Utilizando o banco `mpg`, faça o diagrama de dispersão de `displ` por `hwy` e mapeie a cor para `class`, o tamanho para `cyl` e a forma para `manufacturer`. Como esses atributos estéticos se comportam diferente para variáveis categóricas vs contínuas?

```{r}
ggplot(mpg, aes(
  displ, 
  hwy, 
  color = class, 
  size = cyl,
  shape = manufacturer)) +
  geom_point()
```

Ao cumprir as instruções como dadas, logo de cara você recebe um aviso do `ggplot2`. A paleta de "shapes" só recebe por padrão 6 shapes diferentes, porque de acordo com o autor, mais de 6 torna difícil de distinguir. Mas eu sou teimoso.

```{r}
ggplot(mpg, aes(
  displ, 
  hwy, 
  color = class, 
  size = cyl,
  shape = manufacturer)) +
  geom_point() +
  scale_shape_manual(values = 1:15, guide = "legend")
```

Esse gráfico é mais um exemplo para vocês verem como diferentes escalas se comportam. A variável `cyl` é numérica e ordenada, então faz sentido colocá-la num mapeamento como `size`, já que visualmente é possível indicar que a grandeza aumenta com o tamanho. Classe é uma variável categórica, então ela fica melhor em mapeamentos que ressaltam diferenças entre as categorias, como `colors` ou `shapes`. O pacote também impõe algumas restrições sobre o que é possível mapear. Por exemplo, ele retorna erro se você tenta mapear uma variável discreta para uma escala contínua.

```{r, error = TRUE}
ggplot(mpg, aes(displ, hwy, color = class)) +
  geom_point() +
  scale_color_continuous()
```

Experimentem tentar mapear diferentes variáveis no banco `mpg` para as diferentes escalas e vejam os resultados. Em alguns casos, é possível, mas o gráfico é pouco informativo, em outros, você verá mensagens de erro.

3. Utilizando o `diamonds`, crie um diagrama de dispersão que relacione `carat` com `price`. Explore algumas outras variáveis utilizando escalas de cor para ver se você identifica algum padrão. Aplique transformações nas variáveis que você considerar justificadas.

Esse exercício não tem uma resposta correta. O objetivo era que vocês explorassem as transformações estatísticas e as escalas de cores diferentes presentes no `ggplot`, através do argumento `trans`, ou mesmo fazer outras transformações que interessassem vocês nas variáveis. Abaixo um exemplo de transformação de Yeo-Johnson, um tipo de transformação BoxCox que aceita valores negativos e uma das escalas de cor do pacote `viridis`.

```{r}
ggplot(diamonds, aes(carat, price, color = clarity)) +
  geom_point() +
  scale_x_continuous(trans = scales::yj_trans(p = 2)) +
  scale_color_viridis_d(option = "magma")
```

4. Ainda continuando o exemplo anterior, aplique um `geom_smooth` utilizando várias opções de `method` para as variáveis originais ou transformadas.

Segundo a mesma lógica, o objetivo era explorar as opções de visualização de modelos simples através do argumento `method`. Abaixo um exemplo de `gam`. Uma mudança que fiz foi usar a variável `cut` ao invés de `clarity`, porque o gráfico não-transformado de `clarity` estava muito poluído.

```{r}
ggplot(diamonds, aes(carat, price, color = cut)) +
  geom_point(alpha = 0.1) + # pontos translúcidos para reduzir a poluição
  geom_smooth(method = "gam", se = FALSE) +
  scale_color_viridis_d(option = "plasma")
```

5. No nosso gráfico de barras usando `stat(prop)` a gente precisou colocar `group = 1`, porque? Qual é a diferença entre esses dois códigos?

```{r}
ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, y = after_stat(prop)))
ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, fill = color, y = after_stat(prop)))
```

Acabei explicando isso na aula, devido a uma pergunta, mas para quem perdeu, trata-se do comportamento padrão quando há proporções: cada barra terá sua própria proporção e todas somarão a 100%. O uso de `group = 1` indica à função que as proporções que somam a 100% são o total dos níveis do fator e não cada nível individualmente.

```{r}
ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, y = after_stat(prop), group = 1))

# No caso em que há um "fill", precisamos normalizar as alturas das barras
ggplot(data = diamonds) +
  geom_bar(mapping = aes(
    x = cut,
    y = stat(prop),
    fill = clarity
  ))

ggplot(data = diamonds) +
  geom_bar(mapping = aes(
    x = cut,
    y = stat(count)/sum(stat(count)),
    fill = clarity
  ))
```


6. `stat_smooth` é muito parecido com `geom_smooth`, mas há uma diferença sutil. Compare os códigos abaixo.

`geom_smooth` chama `stat_smooth` quando você utiliza a função para calcular as "médias condicionais" que correspondem a linha de tendência desenhada no gráfico. É assim com todos os `geom`s no pacote. Há uma conexão entre o objeto geométrico e uma transformação estatística. Mesmo que seja a transformação `_identity`, que mantém a variável exatamente como ela estava no dado. A grande vantagem de construir um gráfico com `stat_smooth` ao invés de `geom_smooth` é que você pode especificar outro objeto geométrico que não seja o padrão (`geom_line` + `geom_ribbon`). É isso que os gráficos abaixo demonstram.

```{r}
ggplot(mpg, aes(displ, hwy)) + 
  geom_point() +
  geom_smooth()

ggplot(mpg, aes(displ, hwy)) + 
  geom_point() +
  stat_smooth(geom = "step")

ggplot(mpg, aes(displ, hwy)) + 
  geom_point() +
  stat_smooth(geom = "linerange")
  
ggplot(mpg, aes(displ, hwy)) + 
  geom_point() +
  stat_smooth(geom = "errorbar")

ggplot(mpg, aes(displ, hwy)) + 
  geom_point() +
  stat_smooth(geom = "crossbar")

```

7. Usando o `mpg` e `facet_grid`, crie um scatterplot que contenha `displ` no eixo x, `hwy` no eixo y, `class` na cor, `drv` nas facetas-coluna e `cyl` nas facetas linha.

Esse aqui é para demonstrar o uso de `facet_grid`, que permite especificar fatores de classificação diferentes nas linhas e colunas, diferente de `facet_wrap` mostrado na aula, que só permite especificar uma dimensão.

```{r}
ggplot(mpg, aes(x = displ, y = hwy, color = class)) +
  geom_point() +
  facet_grid(cyl ~ drv)
```

8. Você acha que os dois gráficos abaixo ficarão diferentes um do outro? Porque? Tente responder antes de rodar o código.

```{r}
ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + 
  geom_point() + 
  geom_smooth()

ggplot() + 
  geom_point(data = mpg, mapping = aes(x = displ, y = hwy)) + 
  geom_smooth(data = mpg, mapping = aes(x = displ, y = hwy))
```

Mesmo antes de rodar o código, o observador astuto notará que os mapeamentos locais no segundo gráfico são idênticos entre si e aos mapeamentos globais, então os dois gráficos são iguais.

9. Tente recriar o seguinte gráfico

O objetivo dessa era fazer vocês fuçarem um pouco na ajuda para tentar recriar o mais fielmente possível o gráfico final. Não precisava ter acertado, o objetivo era chegar o mais próximo possível.

```{r}
ggplot(mpg, aes(displ, hwy, color = drv)) +
  geom_point() +
  geom_smooth(method = lm, se = FALSE) +
  labs(x = "Rodovia", y = "Toneladas", color = "Tração") +
  scale_color_brewer(palette = "Set1")
```

10. Transforme o gráfico seguir em um gráfico de pizza usando `coord_polar`.

```{r}
ggplot(diamonds, aes(cut, fill = cut)) +
  geom_bar()
```

Depois de simplesmente especificar `coord_polar`, em geral o gráfico fica meio estranho, não tem aquela cara bonita de pizza. É preciso corrigir os seguintes problemas:

- A largura das barras deve ser igual a proporção das contagens, mas a altura deve ser igual a 1! Portanto, eu inverto as coisas e passo as contagens/proporções para "x" e "y" fica com o valor fixo = 1.

```{r}
ggplot(diamonds, 
       aes(
         # calculando as proporções do total,
         # também funciona com o padrão stat(count)
         x = stat(count)/sum(stat(count)),
         y = 1, # altura igual a 1
         fill = cut)) + # cores
  geom_bar() +
  coord_polar() + # coordenadas polares
  # opcional: remover aspectos do tema para um visual mais clean
  theme_void()
```

Como desafio, tentem adicionar elementos textuais das proporções no gráfico. O problema a ser resolvido é como posicionar o texto num sistema de coordenadas polares. Boa sorte!

Gráficos de pizza são polêmicos na análise de dados porque nossos olhos não captam bem diferenças entre formatos curvos e complexos, então a comparação entre as categorias fica prejudicada se houverem mais de 2 ou 3. Eu sempre dou preferência para barras. Há um tipo de gráfico de pizza melhorzinho chamado "donut plot", em que o meio do círculo é oco, mas eu ainda prefiro as barras.
